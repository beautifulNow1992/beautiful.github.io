<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="掌握java相关知识，擅长大数据，以及机器学习算法应用方面 java scala python"><meta name="keywords" content><meta name="author" content="zhuyuping"><meta name="copyright" content="zhuyuping"><title>朱遇平的github博客</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.0"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">zhuyuping</div><div class="author-info__description text-center">掌握java相关知识，擅长大数据，以及机器学习算法应用方面 java scala python</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">12</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">4</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">朱遇平的github博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="site-info"><div id="site-title">朱遇平的github博客</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2019/07/08/kafka/">我了解的kafka</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-08</time><div class="content"><p>kafka 是个很好分布式消息中间件，但是我个人喜欢把他叫做流存储，下面我从我了解的地方说一下kafka，<br>kafka 架构其实很简单，producer consumer broker 其中broker consumer使用zookeeper 维护topic路径以及消费的相关位置信息。对于用户写有同步异步写，因为中心化系统所以 一主多从，用户发送时候多个队列批量累计异步发送 ack,也有同步ack,不同的是 主 不同步消息到从，而是由从主动从主这边拉取，这样任务可以并行化，同时为了保证C一致性，只有同步好的才能被消费者消费到，但是因为主 跟 从同步的日志记录位置差一次交互，由于存在2将军问题，消息丢失超时各种可能，所以需要使用LEO HW来进行保证读取消息日志同步一直性，这之间可能会出现宕机重启问题，所以为了保证选举一直是最新消息日志的机器，会记录ISR机器，只有ISR机器才能被当选主，后面就是一些常用的套路，分片副本，负载均衡，使用topic 作为namespace隔离 然后key partioner 来做分片，多个topic不同机器master 实现了简单负载均衡，而其中用户写入的消息都有一个唯一的id ,最后通过分片写入到相应的 topic_partion的目录里面，每一个目录里面会记录2个相关文件，每个文件以 offset.index offset.data 开头，比如000000000000001.index ,为了写的高吞吐高性能，数据先写入pagecache 然后定时fsync 或者缓冲到4k 刷新到文件里面，只有刷新到文件里面的才能被consumer消费。<br>用户当读取时候 通过zk获取到offset，然后通过二分查找或者skiplist找到相应的index 文件，为了索引文件快速查找一般加载到pachecache中，同时一些最近的日志也在pagecache中，通过找到相应的index文件，读取里面记录，index为了减少大小，一般采用整数压缩，只记录一些间隔的数据，比如 000000000005 比000000000001 间隔4 会记录 （4,197） 后面表示在offset.data的197位置，而同样他不会连续的记录，比如000000000006 记录可能不会记录（5，220）这条索引，他会等待数据达到4k或者一个间隔时间 记录下次来的新纪录，索引很稀疏。同样通过二分或者skiplist找到offset.data文件，读取相应的文件。里面解析格式，里面有校验码 时间戳 id key key length value valuelength等 这样读取到数据继续，通过zerocopy方式进行发送。实现高性能。<br>因为每一条记录只会追加到文件末尾，所以文件会越来越大，最大支持4G，大体就是这样。这就是我理解的kafka,他为什么这样实现，而不是他是这么实现，这才是我们学习最重要的。其实kafka 虽然我们叫消息中间件，其实很多方面跟分布式存储很相似，其实这些思想都是不变通用的，后面我有时间更新一下spark storm flink</p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/07/12/spark/">我对spark的理解</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-12</time><div class="content"><p>我从2014年底接触spark开始，到后面15年初创业使用spark批量计算图像特征，图像算法，PCA等，LSH hash索引后，就开始对spark产生了浓厚的兴趣，spark 为什么这么高效，为什么spark 速度要比mapreduce快那么多，spark是怎么实现的，他为什么要这么做，他从发展初到现在2.4版本似乎本质的东西一直没有变过，后来我一直使用者，也一直研究看着他的源码设计，有了一些自己的心得体会，终于明白了上面的一些问题。<br>  首先spark 是迭代计算，所以适合那些数据块的处理，不适合那种算法里面各种参数迭代计算，那个需要BSP模型，首先我们spark 分布式计算系统，对于进程来说 无非就是 进程节点状态 与 消息 本地计算的关系，因为spark设计初衷是为了适合计算大批量的数据的问题，所以对于每一个进程节点来说不可能传输数据到每一个节点上进行操作，所以是 节点是数据，而计算是边，计算在节点之间传递的模型。对于我们每一个应用来说，因为是迭代计算，所以从数据输入 到 数据输出，所以他是一个DAG有向无环图，所以spark 的job 是构造成有向无环图的，而因为计算往节点上传输，所以需要有相关的DAG调度管理器，为了多机器并行并发计算所以需要进行任务分片所以肯定也有任务调度管理器，剩下的就是怎么保证数据获取 因为大数据块存储计算 所以需要一个分布式存储引擎，为了保证容错性，需要一致性算法或者机制来保证，为了高效内存计算，所以需要内存缓存管理机制，因为分布式计算系统，多机器，每个任务需要资源不同，所以同样需要进行资源管理机制来分片资源，多台机器上也需要进行相应的资源隔离，最后需要提供相关的编程接口转化为DAG，后来引入了schema,dataframe 引入了sql 以及引擎优化，扩展了相关第三方机器学习包，以及对流数据的支持。</p>
<p>  上面说了那么多，我们大概知道 spark需要有哪些组件。这些可以通过sparkContext sparkEnv可以看得到。比如上面提到的分布式存储，用于计算中间数据存储获取的 BlockManager 为了高速内存获取计算，所以肯定要BlockManager支持memstore diskstore,为了后续扩展使用spi接口，另外前面讲需要DAG解析的 ，对于这个来说我们肯定是在客户端提交任务到多台机器之前解析的，所以我们需要DagScheduler ,对于spark 这种分布式计算架构，因为他只有在map redurce suffle时候进行通讯，他的性能决定都在于shuffle过程 所以他通过DagScheduler分解窄依赖宽依赖，而对于数据源读取统一一个RDD结构，所以数据读取时候有partioner分区，同样因为调度系统 主从架构所以需要有相关RPC通讯 链接管理发起管理命令，启动后台守护，比如用于shuffle的 MapOutputTrackerMaster shufflerFetcher connectionManager ,其他的就是一些守护线程类，因为数据存储获取我们用blockManager来管理了，但是数据一致性完整性，需要一些其他手段了，storm使用了异或特性ack 来维护一个消息的一直完整，flink使用lamport的分布式快照算法来保证一致性，而spark通过lineage 血统来实现，为了能够通过血统恢复，所以RDD会记录父亲RDD的依赖信息，同时要保证RDD只读不变特性，对于每一个spark RDD 分布式弹性数据集结构来说首先blockManager可以维护多机器上数据顺序块存储分区管理，然后当每次迭代调用时候他提供了2中，一种是transformation 一种action 前者是用于RDD之间调用，后缀RDD转为实际值时候操作，所以对于每次迭代操作，都是一个RDD转为另外一个RDD过程，另外的RDD会记录下父亲RDD信息，所以你会发现从HadoopRDD/RDD创建后面的算子 转为MappedRDD ShuffleRDD MapPartionRDD等等过程，而每一个RDD里面执行相应的算子操作，其实就是一个scala函数闭包，转换过程，RDD.iterator 而获取这时候computeOrReadCheckPoint 从缓存本地内存来试着读取数据 ，执行最基本的容器数据迭代转换操作，但是这个过程中数据每次在线程里面不断的迭代处理，其实效率有点低，所以spark做了相关编译生成代码优化，其他都是怎么获取Block块，然后怎么shuffle 的过程，因为在前面我们从Job 到 DagSchuler到Stage 到 task 其实是pipeline手段以及task任务并行化手段，这过程中内存计算迭代 shuffle （Hash-base sort-Base）手段，为了保证多Job运行资源竞争问题，所以有DRF相关资源管理算法。 其实还有很多细节方面，后面为了支持SQL 在RDD算子 上面实现了SQL schema 结构dataFrame，为了能支持spark stream流计算，把流转为一个个Dstream最后代码转为spark 的RDD任务进行执行。<br>  所以总体来说 Spark源码分析可以从：<br>   1.分布式存储BlockManager 贯穿到RDD获取存储 shuffle获取存储里面<br>   2.网络通讯请求Rpc Netty 涉及到后台调度时后台守护线程启动相关以及内部节点相互通讯。这里面有shuffleFetcher MapOutputTracker xxxBackend shuffleBlockManager<br>   3.DAG 计算step pipeline，任务分配 task分解 所以可以看看DagScheduler 以及 TaskScheduler<br>   4.数据一致性 RDD血统实现，checkPointer相关可以结合BlockManager 看看computeOrReadCheckPoint。<br>   大体就是 网络通讯 任务pipeline并行分片调度 资源管理 文件/内存存储  shuffle机制实现等等这些,这些就是spark 源码里面比较核心的一些组件了。</p>
</div><hr></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fa fa-chevron-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By zhuyuping</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.0"></script><script src="/js/fancybox.js?version=1.6.0"></script><script src="/js/sidebar.js?version=1.6.0"></script><script src="/js/copy.js?version=1.6.0"></script><script src="/js/fireworks.js?version=1.6.0"></script><script src="/js/transition.js?version=1.6.0"></script><script src="/js/scroll.js?version=1.6.0"></script><script src="/js/head.js?version=1.6.0"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>