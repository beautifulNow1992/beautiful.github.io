<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="掌握java相关知识，擅长大数据，以及机器学习算法应用方面 java scala python"><meta name="keywords" content><meta name="author" content="zhuyuping"><meta name="copyright" content="zhuyuping"><title>朱遇平的github博客</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.0"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">zhuyuping</div><div class="author-info__description text-center">掌握java相关知识，擅长大数据，以及机器学习算法应用方面 java scala python</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">1</span></a></div></div></div><nav class="no-bg" id="nav"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">朱遇平的github博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="site-info"><div id="site-title">朱遇平的github博客</div><div id="site-sub-title"></div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item article-container"><a class="article-title" href="/2019/02/20/automl/">个人感想以及介绍</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-02-20</time><div class="content"><h3 id="个人思考"><a href="#个人思考" class="headerlink" title="个人思考"></a><strong>个人思考</strong></h3><p>   知识像孤岛，你了解熟悉的知识越广，海岛越大，岛屿边缘海岸线就越长，接触到的未知就越多,感叹自己的无知，我认识了架构业务算法的异曲同工之妙，惊叹设计思想的精妙绝伦，充满着对每一个细节的求知欲，充满着对未知新事物的好奇心，就像发现新大陆的孩子，只想探索每一片角落。仿佛精力无限，只想探索未知给自己一个答案。</p>
<h2 id="求职意向："><a href="#求职意向：" class="headerlink" title="求职意向："></a><strong>求职意向：</strong></h2><p>   希望公司稳定有挑战有发展的大平台，头几年人生道路选择上历经坎坷，小公司要倒闭了，非互联网公司互联网部门快撤销了，创业失败了，从18线互联网一步步爬上来付出了无数的勤奋努力，18年选择来美团没有选对自己的岗位方向，也是人生道路的经验吧，所以下一份工作希望能够对自己有挑战性，方向合适的，能够有机会展现自己的能力的大平台，学习成长自己，因为以前人生道路不顺，简历职业生涯跳槽频繁了，所以下份工作不可能在换了，不然除非不在互联网这个行业了，我对自己的规划也是：技术上.非技术上 软硬实力成长，1.技术上：希望挑战性 复杂性工作，自己想深入系统核心，尝试挑战优化极致，追求完美，自己在空余时间也计划去深入研究分布式存储计算，中间件，分布式计算 其他平台领域，进行源码的庖丁解牛，深入底层，2年内自己有造轮子的能力，2.非技术上提高自己看待事物的方法，沟通理解业务能力，总结一套自己的思想方式模式，对事物能够一个全局观，以及某方面有深刻的认识。  </p>
<h2 id="个人介绍："><a href="#个人介绍：" class="headerlink" title="个人介绍："></a><strong>个人介绍：</strong></h2><p>以前在喜马拉雅平台架构，做了分布式日志监控系统（类似我现在所在美团的Cat+logCentor+天网+XT+数据仓库），分布式风控系统(第三代规则引擎+模型算法)，分布式大数据平台，数据仓库相关核心开发，后来来到美团，负责风控系统rcData数据平台，以及rcfraud审批平台，以前喜马拉雅风控是第三代第四代，这里是第一代。在这期间完成了审批流程抽象抽取，生活费异步审批的封装，人行报告的解析落地。批量大数据处理贷后数据。个人java基础知识扎实，高并发，因为架构qps高，所以对于高并发场景，日常中幂等，降级 熔断 自动扩容，负载均衡，服务化，限流，缓存，分库分区分表，性能调优，大数据，分布式中间件kafaka ,相关newSQL nosql,监控报警，服务编排等手段来解决这方面的问题，术业有专攻，个人比较擅长大数据以及大数据相关体系的技能。懂机器学习算法原理，能够熟练运用使用机器学习算法,深度学习也能运用,在喜马拉雅以及美团以及以前工作有过这方面的开发经验。语言方面：java scala 比较熟练，python sdk没有java scala熟悉，但能写能改。页面也能写一些。因为做的事情很多，这里列出一些关键的擅长的事情：</p>
<p>   1.能够扩展spark source transformer estimator udf 以及UI 支持各类算法 支持python语言跨平台。<br>   2.以前使用过fastText 以及textCNN做文本反垃圾pipline 算法流程。<br>   3.以前做过app流量电量预测使用过特征工程，然后DNN 以及 xgboost 以及 随机森林  然后blend 做喜马拉雅流量电量预测。<br>   4.spark上为了后来使用方便封装了一些常用的套路，支持一些常用的算子 UDF 以及 模式。<br>   5.在用户画像方面尝试过DNN拟合 尝试过LSTM 因为能够熟练用于机器学习框架 深度学习框架，也会写python 所以能够很容易的将python算法代码改成scala spark分布式上运行以及网上开源的各类AI库能够熟练使用运用。<br>   6.特征工程方面也很熟练。<br>   7.了解AI原理，喜欢研究最新的AI成果比如 后面提到的transformers 架构 GAN 强化学习 还是 bert VAE变分，经常自己根据这类的网络设计规则防止过拟合的门结构，残差结构 attention模型 batchNorm 以及激活函数特性来自己设计一些网络去尝试，一直在研究,比如像尝试GAN在kaggle card欺诈样本生成对抗，最后得到的结果在过一次原始的xgboost在样本集上效果挺好。<br>   8.做过分布式日志监控系统，从链式追踪到数据同步以及到最后的数据仓库，从详细表到大宽表到统计表。从spark stream storm 实时计算到 spark hive计算，统计方面从指标变量管理平台到任务调度管理平台，这其中我最擅长自动化，自动代码生成自动模板生成，封装套路<br>   9.风控方面 在喜马拉雅与美团做过变量的计算封装以及数据自动同步，审批框架的抽取封装，审批运维平台管理，频控限流 pie规则引擎（drools动态封装），zk实现的网络分布式设计，自动化的变量计算以及累计服务。<br>  10。做事效率高，不会重复做很多事情，所以在平台架构时候，很多东西全部都是实现自动化的。因为平台架构就我们5个人，但是要做的事情很多，管理排除问题很多，所以很多东西都会自动化封装，即使排查问题，都有一个直观可视化搜索界面，所以页面我也会做，学习东西比较快吧，一个陌生的东西很快就能上手，了解原理。</p>
<h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a><strong>项目介绍</strong></h3><p>   这个项目最近暂时停止开发了，因为剩下大量重复性代码生成包装工作了,（其实也在研究图DAG automl自动构造的方法，看了一些google的paper知道要怎么做了，还有参数动态管理控制的方法也知道怎么做了）有时候在想如果能够实现DAG 拓扑图动态搜索所有可能，自动生成模型，然后对于每一个DAG依赖之间是否可以通过默克尔树来来保证流程完整准确性，进而实现真正的automl 我觉得，真正的automl 应该是不需要用户去拖拉生成DAG的（用户需要知道数据特征工程算法知识，门槛太高了），而应该通过数据以及一些约束 特征工程方式来规划搜索得到最优的DAG流程。以前觉得这个是不太可能的，最近看了google的一些paper发现是可以做到的。</p>
<p>   最近也要开始找工作，上班也有点忙，周末也在研究flink 以及一些newSQL ,个人感觉很多分布式系统 计算 存储 从设计原理思想都有异曲同工，万变不离其宗，我自己打算工作空余，周末空闲时间拆解分布式存储，分布式计算，自己能够深入彻底的从现在理解原理，架构设计思想，到怀疑性能高效，到了解一个分布式（计算/存储/框架）内部每一个个细节，希望不久将来拥有自己能够独立实现一个性能很好的轮子（分布式高性能计算/存储/系统）的能力</p>
<p>   个人从12月底左右空余时间开始想做一个自动化机器学习平台，为什么想做这个平台，一方面是一个学习提升能力项目，一方面是希望能展示自己的能力，另一方面是公司做的东西因为涉及公司机密无法展示，所以想通过这个平台来展示一下自己的能力，因为空余时间有限，周六周末偶尔做一下，所以并没有完整做完，只完成了核心部分，这里就展示一下个人的设计思路链条。</p>
<p>   参考了阿里的PAI ，因为PAI 是中断的，对于每一个节点处理，然后通过airflow类似工作流来管理流程，产生很多中间数据，会依赖很多脚本运行，我的想法是 对于数据读取 数据清洗 数据转换 特征工程 算法模型 超参数优化，这应该是一个pipeline过程，而每一个pipeline 流程可以有上下依赖的关系，这样大的pipeline流程使用airflow来管理依赖，小的pipeline流程直接使用DAG 有向无环图的结构来管理 类似spark 中DAG 管理宽窄依赖使用深度优先遍历来逐步初始化 compose模式搭建积木来构建一个完整流程代码。<br>   首先看看我的设计图</p>
<p>   <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/flowdesigner01.jpg" alt></p>
<p>   从大的方向主要分为四个层：<br>   引擎层、拓扑图层 、UI可视化层、任务调度层<br>   主要原理就是通过对图的构建，通过前端jsplumb可视化技术来实现拖拉生成相关图，然后进行graphml系列化，最后通过DFS 遍历获取每一个节点Node 通过compose模式动态生成相应的引擎代码，交给lts分布式任务系统动态运行job。</p>
<p>   <strong>第一点Graph图构建封装</strong>：是核心类 graph storm中的拓扑图结构，有向无环图DAG 顶点与边组成<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/toplogy%E5%B0%81%E8%A3%85%E9%A1%B6%E7%82%B9%E8%BE%B9.png" alt><br>jgrapht 转为graphml 系列化存储以及jsplumb可视化。<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%B5%81%E7%A8%8Bjsplumb%E4%BB%8Egraphml%E8%BD%BD%E5%85%A5%E5%8F%AF%E8%A7%86%E5%8C%96.png" alt></p>
<p>演示：<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%BF%9B%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9B%E5%BB%BA.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%BF%9B%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9B%E5%BB%BA1.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%BF%9B%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9B%E5%BB%BA2.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%BF%9B%E8%A1%8C%E6%B5%81%E7%A8%8B%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9B%E5%BB%BA%E8%8A%82%E7%82%B9%E5%8F%82%E6%95%B0%E5%80%BC%E8%AE%BE%E7%BD%AE.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%8A%82%E7%82%B9%E7%B1%BB%E5%88%AB.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%8A%82%E7%82%B9%E5%88%97%E8%A1%A8.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E8%8A%82%E7%82%B9%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%B5%81%E7%A8%8B%E9%93%BE%E6%8E%A5%E4%B8%8E%E4%BF%9D%E5%AD%98.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%B5%81%E7%A8%8B%E5%88%9B%E5%BB%BA.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%B5%81%E7%A8%8B%E4%BF%9D%E5%AD%98.png" alt></p>
<p><strong>第二点 spark datasource  transformer estimator封装</strong></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E9%A1%B9%E7%9B%AE%E6%A8%A1%E5%9D%97.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%95%B4%E5%90%88%E4%B8%80%E4%BA%9Bspark%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%BA%9B%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/python%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%E4%BB%A5%E5%8F%8A%E5%B0%81%E8%A3%85.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/pyspark%E4%B8%80%E4%BA%9B%E6%B5%8B%E8%AF%95%E4%BB%A5%E5%8F%8A%E7%89%B9%E5%BE%81%E5%B0%81%E8%A3%85.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/python_template.png" alt></p>
<p>在spark mlib基础<br>整合了spark 一些相关库<br>mmlspark bigDL H2O xgboost lightgbm 另外自己也实现了一些estimator 采样 异常点 以及除去NAN 去除重复，除去高基数，编码等等,自定义扩展了一些数据源比如更好的hbase 阿里云的tablestore 以及 tushare查询A股股票数据。另外因为pyspark py4j关系，所以可以通过py4j 实现python相关方法比如bert 文本特征提取然后scala pyspark可以直接调用，原理是因为 在pyspark中把相关bert处理 注册为UDF，但是这个UDF 是python UDF ，所以在scala 使用时候需要实现相应的转换 转换成UserDefinedPythonFunction 就可以在scala中使用了，同时因为新版本支持pandas_udf 所以可以支持sklearn相关包一些transformer可以使用了。<br>这里我定义了一个tushare 查询A股股票以及bert模型支持（内存占用太大，在解决）。<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/tushare%E6%94%AF%E6%8C%81.png" alt><br>比如fastText预训练模型可以直接pyspark 方式 也可以直接bigDL 来加载，在工作中偶尔会用到，通过bigDL keras 嵌入层 加载 dense层加载方式可以实现estimator， 还有很多比如上下采样实现，还有一些特征工程套路，我就直接使用UDF来定义（pyarrow支持pandas）就好了。<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/fastText01.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/fastText02.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/bert%E6%A8%A1%E5%9E%8B.png" alt></p>
<p>可惜的是bert展示只能本地运行，因为线上依赖预训练模型，需要通过spark addFile addJar 加入来获取地址 spark.get获取相关模型来分布式读取预训练模型，所以这类很多相关的先见依赖的工作。比如pip setup构建python本地包，以及拷贝这类文件工作我后面打算用docker 来管理，使用K8S来自动编排.平时时间不多这一步还没完成 K8S也在研究。</p>
<p>第三部就是 动态代码生成：<br>通过图的遍历，来获取节点，然后搭积木方式来生成相关xml 以及相关代码。这里我完整实现了spring的xml的 构建生成。因为大部分时间在实现spark那些datasource estimatro transformer 自定义udf所以spark的代码只实现了部分。<br>这是spring integation封装<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/springintegration%E5%B0%81%E8%A3%85.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/springintegration%E5%B0%81%E8%A3%852.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E5%BC%82%E6%AD%A5%E5%AE%A1%E6%89%B9%E6%B5%81%E7%A8%8B%E5%B0%81%E8%A3%85.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/%E6%B5%81%E7%A8%8B%E5%9B%BE%E7%A7%AF%E6%9C%A8%E6%9E%84%E5%BB%BA.png" alt><br>对于spark引擎封装主要<br>实现链式<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/python_template.png" alt><br>比如<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/pyspark%20%E9%93%BE%E5%BC%8F.png" alt><br>对于pyspark<br>通过freemarker引擎 来生成spark代码 直接填充pyspark代码链式块就可以了，这一部分因为节点太多，没有完整完成。</p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/spark%E6%9E%84%E5%BB%BA1.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/sparkgoujian2.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/spark%20%E6%9E%84%E5%BB%BA3.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/spark%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E6%96%B9%E5%BC%8F.png" alt></p>
<p>为了方便sdk使用采用<br>stepBuilder构建模式进行约束<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/stepBuilder%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%BC%8F.png" alt></p>
<p>因为spark 的没有封装完，这里演示 spring的版本：<br><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/spring01.png" alt></p>
<p><img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/spring2.png" alt></p>
<p>总结：<br>时间原因过多浪费在页面以及spark 算法 特征工程节点的工作上，以及研究k8s自动编排上并没有完成整个项目，所以这里只演示展示了个人项目的部分代码。个人比较擅长大数据 机器学习算法工程方面。可以熟练使用各类算法 以及深度学习算法在spark中部署应用。能够python scala java 混合开发。能够把python sklearn 相关包大数据工程化。上面这个项目主要是自己学习项目，一方面可以通过这个项目来了解使用各类算法，另外一方面是希望能做一个好的开源项目。后面我打算实现几个方面：<br>  1.引入K8S自动编排<br>  2.实现页面配置python 代码以及Java spi模块插件，动态定义UDF 来自定义数据节点<br>  3.实现BigDL的研究想实现keras 深度学习模型自定义<br>  4.整合成功bert 还有一些常用的深度学习模型 一些常用特征工程套路到spark工具包中。<br>  5.引入sqlparser 扩展SQL引擎使其可以通过SQL 实现机器学习的更便捷查询语法。<br>  6.支持更多可视化比如现在整合的handspark只支持简单的直方图。箱图<br>  7.研究mleap 来尝试实现发布部署sdk 然后通过flink来部署上线进行相关预测。<br>  8.通过个人学习项目来尝试研究图来尝试元学习以及图 来实现一些automl。学习更多的算法知识。</p>
<h2 id="（PS-个人感言：）"><a href="#（PS-个人感言：）" class="headerlink" title="（PS 个人感言：）"></a>（PS 个人感言：）</h2><p>个人成长最大的应该是喜马拉雅吧，跟随从平台架构从无到有，比如推拉模式的分布式配置中心,比如基于zk paxso算法以及raft算法的etcd等思想原理的分布式框架的架构设计，在进一步封装的网关系统，分布式日志系统，数据仓库搭建，比如基于docker以及后来的k8s的cmdb发布平台，spark 流与离线日志统计报警监控，日志管理搜索，storm增量同步，爬虫舆情webdriver 分布式代理抓取，算法机器学习风控，文本评论反垃圾的运用，图算法LPA 欺诈账号，刷播放账号的寻找。opentsdb图表统计可视化，后来来到美团发现整个公司的技术栈都很熟悉了解，很多曾经参与做过。很感谢喜马拉雅，个人学习能力很强，特别喜欢多思考一步，每次都会反省自己，喜欢碎片化学习，总结提炼自己的架构经验算法工程能力，特别希望有这样一个平台表现自己。现在在金融部门虽然，在这里我给rcdata实现了自动化数据同步，指标变量管理，自动化审批平台，后台运维管理，但是并没有体现自己在架构大数据算法工程上的能力，风控偏向第一代初期的规则引擎的相关操作，我本来期望来到这里能够实现一套从用户申请，然后数据指标计算，自动化特征工程，从实时宽表到离线宽表，从数据源到数据输出，从批量到实时，从DAG流程节点管理到算法模型pipeline,最后到强化学习自动反馈机制自动更新模型也想尝试引入ftrl 用一些深度学习来做尝试，最后统筹数据接入到图计算 图谱一些AI算法的尝试上形成一条完整的链，从数据接入 模型预测，图推理，数据统计 形成一个完整的链路环。用户每笔申请，每一笔还款，用户上次还款这次还款时间，等等 用户各类行为，都能够自动的生成各类维度的指标变量（自己总结的特征工程变量套路）甚至每天不同时间的申请量 都可以采用ARIMA以及相应的prophet ,AI相关前馈网络 LSTM transfomers结构 HTT等时间系列算法来预测每天不同时间的申请量，来进行相应的限流控制，预测评估。最后做到AIOps ，下面这个项目就是我平时周六周日做的，原因说过了，其实最开始初衷是想实现 从数据源到数据输出，大数据算法AIOps化。能够应用到股票其他相关预测中，最后通过强化学习自动调整深度学习网络，设计网络来做到自我强化，然后可以生成SDK 可以手机微信号监控可视化展示，能够自动模型部署上线进行各类预测。 </p>
</div><hr></div><div class="recent-post-item article-container"><a class="article-title" href="/2019/05/07/image-model/">2019-05-08 图像方面的一些尝试</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-05-07</time><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/图像方面的一些探索笔记/">图像方面的一些探索笔记</a></span><div class="content"><p>我其实以前做过很多算法学习尝试，跟我博客写的那样，其实也偶尔碎片时间学习一下最近的paper算法，我学习能力比较强，虽然精力有限，但是我觉得知道很多广的知识面，你可以有很多思路解决各类无边界跨领域的问题，其实做大数据，像spark core<br>stream mlib graphx ,core其实就是需要大数据方面掌握 离线的计算，设计，存储一些知识，stream流计算实时计算（flink storm） mlib使用就是需要你掌握机器学习 深度学习算法你才能使用，graphx 就需要你掌握图论以及一些LPA deepwalk GNN图深度学习 GMN 图像匹配网络 pregel模式 社区检测 强连通图，跟进一步可能就是知识图谱RDF 主谓宾，所以感觉要研究的东西还有很多，所以我觉得我一直摸透spark 每一个细节 spark里面涉及的相关知识，设计细节，就有很多值得学习的。废话不多说<br>    最近晚上空余时间在查阅google一些paper 怎么实现动态生成深度学习网络（当然是一些现有的通用模块），研究了一些图像CNN 最新的改进，从alexNet 到 vgg 到googleNet<br>到denseNet 到 XInception  到 capusleNet （胶囊网络）到 MobileNet  到 ShuffleNet 以及到最新把transformer 注意力机制应用到CNN上的NleNet，从 group conv 分组卷积 到 空洞卷积 到 local conv 卷积 到 1x1 3x3 inception 链接结构 还有 concat add的 残差skip connection结构 bottleneck结构 到 depthwise 结构 sufflechannel改进,到注意力机制结构，到多遍分路结构，大体来说 2个方面 1方面 从卷积角度来说改进更小的参数，更灵活的变动 另一方面 从网络总体角度 更好的收敛，更好的模式。<br>所以后面我打算 先做一个基本模型，然后尝试着 套上 group conv 残差bottleneck残差结构 空洞卷积<br>depthwise卷积 和 pointwise卷积 多路结构 最后 结合GAN生成网络来实现一个模型来试试 。</p>
<p>2019年5月7号晚上：<br>  我在网络上下载了一个keras 的项目作为baseline 来修改，这是一个训练衣服颜色 以及 种类的模型，我刚搭建起来 运行训练了一下：</p>
<p>  这个模型挺有意思，他有2个输出，为啥用它就是 因为这样就是一个DAG，而不是一个最常见的系列方式，可能有多个输入或者多个输出，他的输出一个是颜色 一个是种类，<br>  先看看训练数据源<br>  就是一些物品 标记了颜色以及种类，可以用 kaggle的水果数据来做训练更大更齐全<br>  <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-105525%402x.png" alt><br>  <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-105548%402x.png" alt><br>  原始的网络设计<br>  <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/keras_multi_output_fashionnet_top.png" alt><br>  <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/keras_multi_output_fashionnet_bottom.png" alt></p>
<p>  我下载后重新训练了一下，很快本地就训练完了,执行预测效果如下：<br>  <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-000455%402x.png" alt></p>
<p>  我们可以先看看它内部代码，无非就是卷积池化卷积，我们先不动他链接关系：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = MaxPooling2D(pool_size=(3, 3))(x)</span><br><span class="line">x = Dropout(0.25)(x)</span><br><span class="line"></span><br><span class="line"># (CONV =&gt; RELU) * 2 =&gt; POOL</span><br><span class="line">x = Conv2D(64, (3, 3), padding=&quot;same&quot;)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = Conv2D(64, (3, 3), padding=&quot;same&quot;)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = MaxPooling2D(pool_size=(2, 2))(x)</span><br><span class="line">x = Dropout(0.25)(x)</span><br><span class="line"></span><br><span class="line"># (CONV =&gt; RELU) * 2 =&gt; POOL</span><br><span class="line">x = Conv2D(128, (3, 3), padding=&quot;same&quot;)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = Conv2D(128, (3, 3), padding=&quot;same&quot;)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = MaxPooling2D(pool_size=(2, 2))(x)</span><br><span class="line">x = Dropout(0.25)(x)</span><br><span class="line"></span><br><span class="line"># define a branch of output layers for the number of different</span><br><span class="line"># clothing categories (i.e., shirts, jeans, dresses, etc.)</span><br><span class="line">x = Flatten()(x)</span><br><span class="line">x = Dense(256)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization()(x)</span><br><span class="line">x = Dropout(0.5)(x)</span><br><span class="line">x = Dense(numCategories)(x)</span><br><span class="line">x = Activation(finalAct, name=&quot;category_output&quot;)(x)</span><br><span class="line"></span><br><span class="line"># return the category prediction sub-network</span><br><span class="line">return x</span><br></pre></td></tr></table></figure>
<p> 我们试着尝试使用depthwise卷积替代现有的卷积，后面几天尝试再改链接方式 使用skip connection看看。首先看看depthwise 卷积概念，就是深度上每个channel进行卷积得到featureMap，之后再用1x1卷积来进行卷积， 可以大大减少参数，<br> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/20170825221844235%20%281%29.bmp" alt></p>
<p> 我们直接使用官方仓库models 引入mobileNet里面看看实现就可以了<br> 官方仓库地址</p>
<p><a href="https://github.com/fchollet/deep-learning-models" target="_blank" rel="noopener"> https://github.com/fchollet/deep-learning-models</a><br> 看到了他的实现了。我们现在参考官方库修改一下我们的</p>
<figure class="highlight plain"><figcaption><span>CONV </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">x = DepthwiseConv2D((3, 3), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = BatchNormalization()(x)</span><br><span class="line">x = Conv2D(32, (1, 1), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = MaxPooling2D(pool_size=(3, 3))(x)</span><br><span class="line">x = Dropout(0.25)(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># x = DepthwiseConv2D(32, (3, 3), padding=&quot;same&quot;)(x)</span><br><span class="line"># x = Activation(&quot;relu&quot;)(x)</span><br><span class="line"># x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line"># x = MaxPooling2D(pool_size=(3, 3))(x)</span><br><span class="line"># x = Dropout(0.25)(x)</span><br><span class="line"></span><br><span class="line"># (CONV =&gt; RELU) * 2 =&gt; POOL</span><br><span class="line">x = DepthwiseConv2D((3, 3), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = BatchNormalization()(x)</span><br><span class="line">x = Conv2D(64, (1, 1), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = DepthwiseConv2D((3, 3), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = BatchNormalization()(x)</span><br><span class="line">x = Conv2D(64, (1, 1), padding=&quot;same&quot;, use_bias=False)(x)</span><br><span class="line">x = Activation(&quot;relu&quot;)(x)</span><br><span class="line">x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">x = MaxPooling2D(pool_size=(2, 2))(x)</span><br><span class="line">x = Dropout(0.25)(x)</span><br></pre></td></tr></table></figure>
<p>网络我并没有采用MobileNet2 的跟残差结合的模块，也没有使用shuffleNet的chanelsuffle的方式，就是采用MobileNet1的直接方式。我修改了其中部分代码，注释的是源代码</p>
<p> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-012726%402x.png" alt></p>
<p> 下面来训练看看效果</p>
<p> 开始训练<br> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-030948%402x.png" alt><br> epoll迭代中<br> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-032313%402x.png" alt><br> 最后训练完成：</p>
<p> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-103642%402x.png" alt></p>
<p> 最后进行预测：<br> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-104033%402x.png" alt></p>
<p> 结果比较：<br> 好像更稳定了些,准确率低了一些<br> <img src="http://autometis.oss-cn-shanghai.aliyuncs.com/automl/WX20190508-104226%402x.png" alt></p>
<p> 明天后天晚上下班到家后，我再在spark 上scala实现一下上面这个深度网络并使用spark 来训练预测，后面再慢慢修改网络引入最新的一些特性结构</p>
<p> PS(我最近有个想法想要去尝试一下就是多个GAN模式 来整合yolov3 以及 mobileNetV2 实现对象侦测以及图像识别，然后多个GAN之间实现拓扑图，实现一个可以配置的超级GAN 网络。为什么有这个想法是因为GAN网络 一直依赖由于他的先天性，这种纳什均衡竞争关系，跟我们人一样不断有竞争对抗才会成长，最后看到的效果也一直非常好，<br>所以才有这个打算。) </p>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By zhuyuping</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.0"></script><script src="/js/fancybox.js?version=1.6.0"></script><script src="/js/sidebar.js?version=1.6.0"></script><script src="/js/copy.js?version=1.6.0"></script><script src="/js/fireworks.js?version=1.6.0"></script><script src="/js/transition.js?version=1.6.0"></script><script src="/js/scroll.js?version=1.6.0"></script><script src="/js/head.js?version=1.6.0"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>