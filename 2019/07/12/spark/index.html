<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="我对spark的理解"><meta name="keywords" content><meta name="author" content="zhuyuping"><meta name="copyright" content="zhuyuping"><title>我对spark的理解 | 朱遇平的github博客</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.0"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">zhuyuping</div><div class="author-info__description text-center">掌握java相关知识，擅长大数据，以及机器学习算法应用方面 java scala python</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">4</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">朱遇平的github博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">我对spark的理解</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-12</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>我从2014年底接触spark开始，到后面15年初创业使用spark批量计算图像特征，图像算法，PCA等，LSH hash索引后，就开始对spark产生了浓厚的兴趣，spark 为什么这么高效，为什么spark 速度要比mapreduce快那么多，spark是怎么实现的，他为什么要这么做，他从发展初到现在2.4版本似乎本质的东西一直没有变过，后来我一直使用者，也一直研究看着他的源码设计，有了一些自己的心得体会，终于明白了上面的一些问题。<br>  首先spark 是迭代计算，所以适合那些数据块的处理，不适合那种算法里面各种参数迭代计算，那个需要BSP模型，首先我们spark 分布式计算系统，对于进程来说 无非就是 进程节点状态 与 消息 本地计算的关系，因为spark设计初衷是为了适合计算大批量的数据的问题，所以对于每一个进程节点来说不可能传输数据到每一个节点上进行操作，所以是 节点是数据，而计算是边，计算在节点之间传递的模型。对于我们每一个应用来说，因为是迭代计算，所以从数据输入 到 数据输出，所以他是一个DAG有向无环图，所以spark 的job 是构造成有向无环图的，而因为计算往节点上传输，所以需要有相关的DAG调度管理器，为了多机器并行并发计算所以需要进行任务分片所以肯定也有任务调度管理器，剩下的就是怎么保证数据获取 因为大数据块存储计算 所以需要一个分布式存储引擎，为了保证容错性，需要一致性算法或者机制来保证，为了高效内存计算，所以需要内存缓存管理机制，因为分布式计算系统，多机器，每个任务需要资源不同，所以同样需要进行资源管理机制来分片资源，多台机器上也需要进行相应的资源隔离，最后需要提供相关的编程接口转化为DAG，后来引入了schema,dataframe 引入了sql 以及引擎优化，扩展了相关第三方机器学习包，以及对流数据的支持。</p>
<p>  上面说了那么多，我们大概知道 spark需要有哪些组件。这些可以通过sparkContext sparkEnv可以看得到。比如上面提到的分布式存储，用于计算中间数据存储获取的 BlockManager 为了高速内存获取计算，所以肯定要BlockManager支持memstore diskstore,为了后续扩展使用spi接口，另外前面讲需要DAG解析的 ，对于这个来说我们肯定是在客户端提交任务到多台机器之前解析的，所以我们需要DagScheduler ,对于spark 这种分布式计算架构，因为他只有在map redurce suffle时候进行通讯，他的性能决定都在于shuffle过程 所以他通过DagScheduler分解窄依赖宽依赖，而对于数据源读取统一一个RDD结构，所以数据读取时候有partioner分区，同样因为调度系统 主从架构所以需要有相关RPC通讯 链接管理发起管理命令，启动后台守护，比如用于shuffle的 MapOutputTrackerMaster shufflerFetcher connectionManager ,其他的就是一些守护线程类，因为数据存储获取我们用blockManager来管理了，但是数据一致性完整性，需要一些其他手段了，storm使用了异或特性ack 来维护一个消息的一直完整，flink使用lamport的分布式快照算法来保证一致性，而spark通过lineage 血统来实现，为了能够通过血统恢复，所以RDD会记录父亲RDD的依赖信息，同时要保证RDD只读不变特性，对于每一个spark RDD 分布式弹性数据集结构来说首先blockManager可以维护多机器上数据顺序块存储分区管理，然后当每次迭代调用时候他提供了2中，一种是transformation 一种action 前者是用于RDD之间调用，后缀RDD转为实际值时候操作，所以对于每次迭代操作，都是一个RDD转为另外一个RDD过程，另外的RDD会记录下父亲RDD信息，所以你会发现从HadoopRDD/RDD创建后面的算子 转为MappedRDD ShuffleRDD MapPartionRDD等等过程，而每一个RDD里面执行相应的算子操作，其实就是一个scala函数闭包，转换过程，RDD.iterator 而获取这时候computeOrReadCheckPoint 从缓存本地内存来试着读取数据 ，执行最基本的容器数据迭代转换操作，但是这个过程中数据每次在线程里面不断的迭代处理，其实效率有点低，所以spark做了相关编译生成代码优化，其他都是怎么获取Block块，然后怎么shuffle 的过程，因为在前面我们从Job 到 DagSchuler到Stage 到 task 其实是pipeline手段以及task任务并行化手段，这过程中内存计算迭代 shuffle （Hash-base sort-Base）手段，为了保证多Job运行资源竞争问题，所以有DRF相关资源管理算法。 其实还有很多细节方面，后面为了支持SQL 在RDD算子 上面实现了SQL schema 结构dataFrame，为了能支持spark stream流计算，把流转为一个个Dstream最后代码转为spark 的RDD任务进行执行。<br>  所以总体来说 Spark源码分析可以从：<br>   1.分布式存储BlockManager 贯穿到RDD获取存储 shuffle获取存储 spark所有方方面面里面。<br>   2.网络通讯请求Rpc akka/Netty 涉及到后台调度时后台守护线程启动相关以及内部节点相互通讯。这里面有shuffleFetcher MapOutputTracker xxxBackend shuffleBlockManager值得一看<br>   3.DAG 计算step pipeline，任务分配 task分解 所以可以看看DagScheduler 以及 TaskScheduler<br>   4.数据一致性 RDD血统实现，checkPointer相关可以结合BlockManager 看看computeOrReadCheckPoint。<br>   大体就是 网络通讯 任务pipeline并行分片调度 资源管理 文件/内存存储  shuffle机制实现等等这些,这些就是spark 源码里面比较核心的一些组件了。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">zhuyuping</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2019/07/12/spark/">http://yoursite.com/2019/07/12/spark/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/07/16/bazhanting/"><i class="fa fa-chevron-left">  </i><span>拜占庭问题</span></a></div><div class="next-post pull-right"><a href="/2019/07/08/kafka/"><span>我了解的kafka</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By zhuyuping</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.0"></script><script src="/js/fancybox.js?version=1.6.0"></script><script src="/js/sidebar.js?version=1.6.0"></script><script src="/js/copy.js?version=1.6.0"></script><script src="/js/fireworks.js?version=1.6.0"></script><script src="/js/transition.js?version=1.6.0"></script><script src="/js/scroll.js?version=1.6.0"></script><script src="/js/head.js?version=1.6.0"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>